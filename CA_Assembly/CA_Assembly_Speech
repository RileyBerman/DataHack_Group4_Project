# --- CA State Assembly Speeches --- #
rm(list = ls())
# --- Load Libraries --- #
library(rvest)
library(tidyverse)
library(lubridate)

# Group A (standard asmdc.org structure)
group_a <- tribble(
  ~name,               ~base_url,                 ~pages,
  "Dawn Addis",        "https://a30.asmdc.org",   9,
  "Marc Berman",       "https://a23.asmdc.org",   21,
  "Mia Bonta",         "https://a18.asmdc.org",   3,
  "Juan Carillo",      "https://a39.asmdc.org",   1,
  "Pilar Schiavo",     "https://a40.asmdc.org",   7,
  "Tasha Boerner",     "https://a77.asmdc.org",   14
)

# Group B (asmrc.org structure with /category/press-release/page/N/)
group_b <- tribble(
  ~name,                 ~base_url,                   ~pages,
  "Josh Hoover",         "https://ad07.asmrc.org",    6,
  "Joe Patterson",       "https://ad05.asmrc.org",    4,
  "Leticia Castillo",    "https://ad58.asmrc.org",    0,
  "Heather Hadwick",     "https://ad01.asmrc.org",    0
)

# --- Getting Links for Group A -- #
get_links_group_a <- function(base_url, n_pages) {
  press_url_base <- paste0(base_url, "/press-releases?page=")
  
  relative_links <- map(0:(n_pages - 1), function(page_num) {
    url <- paste0(press_url_base, page_num)
    page <- read_html(url)
    
    page |>
      html_nodes("a") |>
      html_attr("href") |>
      str_subset("^/press-releases/") |>
      unique()
  }) |> 
    unlist() |> 
    unique()
  
  full_links <- paste0(base_url, relative_links)
  
  return(full_links)
}


# --- Getting Links for Group A -- #
get_links_group_b <- function(base_url, n_pages) {
  map(1:n_pages, function(page_num) {
    url <- paste0(base_url, "/category/press-release/page/", page_num, "/")
    
    page <- tryCatch(read_html(url), error = function(e) return(NULL))
    if (is.null(page)) return(character(0))
    
    # FIXED: Use correct CSS selector
    links <- page |>
      html_nodes("h2.entry-title a") |>
      html_attr("href") |>
      str_subset("^https://") |>
      unique()
    
    return(links)
  }) |> unlist() |> unique()
}


# Define article extraction
get_article_text <- function(link, legislator_name) {
  Sys.sleep(1)
  
  page <- tryCatch(read_html(link), error = function(e) return(NULL))
  if (is.null(page)) return(NULL)
  
  title <- page |> html_node("h1") |> html_text2()
  paragraphs <- page |> html_nodes("p") |> html_text2()
  full_text <- paste(paragraphs, collapse = "\n")
  
  # Try structured time tag
  date <- page |> html_node("time.datetime") |> html_attr("datetime") |> ymd_hms(quiet = TRUE)
  
  # Try generic time
  if (is.na(date)) {
    date <- page |> html_node("time") |> html_attr("datetime") |> ymd_hms(quiet = TRUE)
  }
  
  # Try div.submitted-date (asmrc structure)
  if (is.na(date)) {
    date_text <- page |> html_node("div.submitted-date") |> html_text2()
    date <- parse_date_time(date_text, orders = c("mdy", "B d, Y"), quiet = TRUE)
  }
  
  # Fall back to NA if still missing
  if (is.na(date)) date <- NA
  
  # Safeguard against missing fields
  if (is.na(title) || full_text == "") return(NULL)
  
  tibble(
    legislator_name = legislator_name,
    title = title,
    date = as.Date(date),
    source_type = "press_release",
    topic = NA,
    full_text = full_text,
    url = link
  )
}

all_speeches <- list()

# Group A scraping
for (i in seq_len(nrow(group_a))) {
  name <- group_a$name[i]
  base_url <- group_a$base_url[i]
  n_pages <- group_a$pages[i]
  
  message("Scraping (Group A): ", name)
  links <- get_links_group_a(base_url, n_pages)
  speeches <- map_dfr(links, ~ get_article_text(.x, name))
  all_speeches[[name]] <- speeches
}

# Group B scraping
for (i in seq_len(nrow(group_b))) {
  name <- group_b$name[i]
  base_url <- group_b$base_url[i]
  n_pages <- group_b$pages[i]
  
  message("Scraping (Group B): ", name)
  links <- get_links_group_b(base_url, n_pages)
  message("Found ", length(links), " links for ", name)
  speeches <- map_dfr(links, ~ get_article_text(.x, name))
  all_speeches[[name]] <- speeches
}

# Combine and write CSV
final_data <- bind_rows(all_speeches)
write_csv(final_data, "all_11_press_releases.csv")
